{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a38b6cbd-16fd-4845-b075-e981e04d2878",
   "metadata": {},
   "source": [
    "# Gradient Accumulation\n",
    "Deep learning models are getting bigger and bigger. For training it becomes difficult to fit large batches as we might run out of GPU Memory. As a result, we are sometimes forced to use small batches during training, which may lead to a slower convergence and lower accuracy.\n",
    "\n",
    "Gradient accumulation allows us to increase the effective batch size. We will use a small batch size but save the gradients and update network weights once every few of batches.\n",
    "\n",
    "Below is a Gradient Accumulation example using MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35c1dc1d-4824-46e7-be6b-52632648fcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import idx2numpy\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import trange\n",
    "\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff34367d-0545-49de-b7b2-db64cdb59b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = '../data/mnist/train-images-idx3-ubyte'\n",
    "train_labels = '../data/mnist/train-labels-idx1-ubyte'\n",
    "test_file = '../data/mnist/t10k-images-idx3-ubyte'\n",
    "test_labels = '../data/mnist/t10k-labels-idx1-ubyte'\n",
    "x_train = idx2numpy.convert_from_file(train_file)\n",
    "y_train = idx2numpy.convert_from_file(train_labels)\n",
    "x_test = idx2numpy.convert_from_file(test_file)\n",
    "y_test = idx2numpy.convert_from_file(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c017968-7c7d-4866-b8bb-08cf885a6125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x168c63310>, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[20]), y_train[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b790e5b-641a-4535-b3ee-8f561dbf8037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4887ab0f-9cda-443f-b868-c467cf201ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(784, 128)\n",
    "        self.l2 = nn.ReLU()\n",
    "        self.l3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.l3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54416402-0720-4320-a809-f6a86cbd21bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy(model, x_test, y_test):\n",
    "    x_test = torch.tensor(x_test.reshape(-1, 28*28)).float()\n",
    "    y_test = torch.tensor(y_test)\n",
    "    # Model is trained now\n",
    "    # Call it on Test Data and see the accuracy\n",
    "    labels = model(x_test).argmax(1)\n",
    "    accuracy = (labels == y_test).float().mean()\n",
    "    print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef5e5be-3dd6-4f16-824f-489366e4165f",
   "metadata": {},
   "source": [
    "## Training without Gradient Accumulation\n",
    "Parameters: \n",
    "- Mini Batch Size (per forward pass) = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91546a66-c767-4689-9640-678953d806ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training without Gradient Accumulation\n",
    "def train_without_grad_accum(model, x_train, y_train):\n",
    "    # Data Preprocess\n",
    "    x_train = torch.tensor(x_train.reshape(-1, 28*28)).float()\n",
    "    y_train = torch.tensor(y_train)\n",
    "    \n",
    "    # Training Loop\n",
    "    iters = 5000\n",
    "    batch_size = 32\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for i in (t := trange(iters)):\n",
    "        # Batches\n",
    "        ix = torch.randint(0, x_train.shape[0], (batch_size, ))\n",
    "        x, y = x_train[ix], y_train[ix]\n",
    "        \n",
    "        # Forward pass\n",
    "        out = model(x)\n",
    "    \n",
    "        # Calc Loss\n",
    "        loss = loss_fn(out, y)\n",
    "        \n",
    "        accuracy = (torch.argmax(out, dim=1) == y).float().mean()\n",
    "        t.set_description(f\"loss: {loss.item()}, acc: {accuracy}\")\n",
    "    \n",
    "        # Zero grad\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # Backward Pass\n",
    "        loss.backward()\n",
    "    \n",
    "        # Update Gradients\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4241d8ea-bdd7-4dd8-bba9-4bff726229ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.08066586405038834, acc: 0.96875: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:06<00:00, 723.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.947700023651123\n"
     ]
    }
   ],
   "source": [
    "model1 = ImageNet()\n",
    "train_without_grad_accum(model1, x_train, y_train)\n",
    "print_accuracy(model1, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e14c25e-81e1-4c23-82e0-cff49558816c",
   "metadata": {},
   "source": [
    "## Training with Gradient Accumulation\n",
    "Parameters: \n",
    "- Mini Batch Size = 256\n",
    "- Micro Batch Size (per forward pass) = 32\n",
    "- Gradient Accumulation Steps = 8 (256 / 32)\n",
    "\n",
    "One thing to keep in mind is that the averaged loss calculation has to be updated as the loss that comes out of `loss_fn` only computes the average based on micro_batch_size.\n",
    "```\n",
    "loss -> Averaged for 32 samples (micro batch), but the batch size to consider to compute the entire loss for the batch is 256.\n",
    "updated_loss = loss / grad_accum_steps\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10196d61-d165-4ce7-b116-54ccffd707a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training without Gradient Accumulation\n",
    "def train_with_grad_accum(model, x_train, y_train):\n",
    "    # Data Preprocess\n",
    "    x_train = torch.tensor(x_train.reshape(-1, 28*28)).float()\n",
    "    y_train = torch.tensor(y_train)\n",
    "    \n",
    "    # Training Loop\n",
    "    iters = 5000\n",
    "    batch_size = 256\n",
    "    micro_batch_size = 32\n",
    "    grad_accum_steps = batch_size // micro_batch_size\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    print(f\"Mini Batch Size: {batch_size}, Micro Batch Size: {micro_batch_size}, Grad Accum Steps: {grad_accum_steps}\")\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for i in (t := trange(iters)):\n",
    "        # Zero grad\n",
    "        optimizer.zero_grad()\n",
    "        loss_accum = 0.0\n",
    "        for step in range(grad_accum_steps):\n",
    "            # Micro Batches\n",
    "            ix = torch.randint(0, x_train.shape[0], (micro_batch_size, ))\n",
    "            x, y = x_train[ix], y_train[ix]\n",
    "            \n",
    "            # Forward pass\n",
    "            out = model(x)\n",
    "        \n",
    "            # Calc Loss\n",
    "            loss = loss_fn(out, y)\n",
    "\n",
    "            loss = loss / grad_accum_steps\n",
    "\n",
    "            loss_accum += loss.detach()\n",
    "\n",
    "            # Backward Pass\n",
    "            loss.backward()\n",
    "\n",
    "        t.set_description(f\"loss: {loss_accum.item()}\")\n",
    "\n",
    "        # Update Weights only after Gradients are accumulated\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70c55260-3a30-4715-ba49-477d905ecc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mini Batch Size: 256, Micro Batch Size: 32, Grad Accum Steps: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.04732232913374901: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:18<00:00, 274.17it/s]\n"
     ]
    }
   ],
   "source": [
    "model2 = ImageNet()\n",
    "train_with_grad_accum(model2, x_train, y_train)\n",
    "# print_accuracy(model1, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5657602-9574-4bb0-aec0-a7364c7d6a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.961899995803833\n"
     ]
    }
   ],
   "source": [
    "print_accuracy(model2, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec17efd5-379b-4d52-afcc-b31be6218d1a",
   "metadata": {},
   "source": [
    "#### Note: Accuracy Increased with Bigger batch sizes per iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80171521-5561-47a8-97ca-440c07cafaad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
